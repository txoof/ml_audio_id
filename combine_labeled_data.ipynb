{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2bf92d4f-92b4-4380-8a6b-ff205a36b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import ace_tools_open as tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80fe52fd-7112-4af5-997d-7b31431a5e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20241106.0824'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestr = time.strftime('%Y%m%d.%H%M')\n",
    "timestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e2a223f9-b2ff-4a89-84f4-4ab6bd65b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate items found. Ready to proceed with 539 labeled items\n",
      "Writing combined labels to file: ./combined_labels_20241106-08H34M.csv\n"
     ]
    }
   ],
   "source": [
    "# Load the labeled data from the CSV and JSON files\n",
    "features_file_path = \"./241103_1441_features.csv\" \n",
    "label_file_path = \"./track_classifications_241103.json\"\n",
    "both_file_path = \"./00_refined_both_playlist_classification.csv\"  # Replace with your actual refined file paths\n",
    "dialogue_file_path = \"./00_refined_dialogue_playlist_classification.csv\"\n",
    "music_file_path = \"./00_refined_music_playlist_classification.csv\"\n",
    "training_path = './TRAINING_DATA/PREPARED/outro/'\n",
    "timestr = time.strftime('%Y%m%d-%HH%MM')\n",
    "combined_labels_csv_path = f'./combined_labels_{timestr}.csv'\n",
    "\n",
    "# Load the labeled data from the JSON file\n",
    "with open(label_file_path, \"r\") as label_file:\n",
    "    labels_dict = json.load(label_file)\n",
    "\n",
    "# Load classification files\n",
    "both_df = pd.read_csv(both_file_path)\n",
    "dialogue_df = pd.read_csv(dialogue_file_path)\n",
    "music_df = pd.read_csv(music_file_path)\n",
    "labels_df = pd.DataFrame(list(labels_dict.items()), columns=['Filename', 'Label'])\n",
    "\n",
    "# Load feature data\n",
    "features_df = pd.read_csv(features_file_path)\n",
    "\n",
    "# rename columns\n",
    "for i in [both_df, dialogue_df, music_df]:\n",
    "    i.rename(columns={'Classification': 'Label'}, inplace=True)\n",
    "\n",
    "\n",
    "# combine all the tagged files into one consistent dataframe\n",
    "sources = {\n",
    "    both_file_path: both_df,\n",
    "    dialogue_file_path: dialogue_df,\n",
    "    music_file_path: music_df,\n",
    "    label_file_path: labels_df\n",
    "}\n",
    "\n",
    "classification_map_dict = {\n",
    "    'B': 'Both',\n",
    "    'M': 'Music',\n",
    "    'D': 'Dialogue'\n",
    "}\n",
    "\n",
    "# standardize values in the data sources\n",
    "for file_path, df in sources.items():\n",
    "    df['Source'] = file_path\n",
    "    \n",
    "    # fix filenames that are not appropriately formatted using a mask\n",
    "    mask = ~df['Filename'].str.startswith(training_path)\n",
    "    df.loc[mask, 'Filename'] = training_path + df.loc[mask, 'Filename']\n",
    "\n",
    "    # # ensure that all the files use consistent labeling\n",
    "    df['Label'] = df['Label'].replace(classification_map_dict).fillna(df['Label'])\n",
    "\n",
    "# standardize the path in the feature file\n",
    "features_df['Filename'] = features_df['Filename'].str.replace(r'.*/outro/', training_path, regex=True)\n",
    "\n",
    "# combine all the sources into a single file\n",
    "combined_labels_df = pd.concat(list(sources.values()), ignore_index=True)\n",
    "\n",
    "# find any tracks that have duplicate entries from muliple sources\n",
    "duplicate_df = combined_labels_df[combined_labels_df.duplicated(keep=False)]\n",
    "if len(duplicate_df) > 0:\n",
    "    print(f\"{len(duplicate_df)} items found. These items may have conflicting tags. Explore below\")\n",
    "    tools.display_dataframe_to_user(name=\"Duplicate Rows in DataFrame\", dataframe=duplicate_df)\n",
    "else:\n",
    "    print(f'No duplicate items found. Ready to proceed with {len(combined_labels_df)} labeled items')\n",
    "    print(f'Writing combined labels to file: {combined_labels_csv_path}')\n",
    "    combined_labels_df.to_csv(combined_labels_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a7c24e7c-bd9f-49d3-a7b3-dffe2bf54a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge combined_df with features_df on 'Filename'\n",
    "merged_df = pd.merge(combined_labels_df, features_df, on='Filename', how='inner')\n",
    "merged_df.to_csv('labeled_tracks_with_features_241106.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cd3919a6-a6cc-4101-be64-00a8ddb260dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_complete = pd.merge(combined_labels_df, features_df, on='Filename', how='right')\n",
    "merged_complete.to_csv('features_with_filename_some_labels_241106.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f943806-b4d8-4d0c-817b-04a72176bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = pd.read_csv('labeled_tracks_with_features_241106.csv')\n",
    "\n",
    "# # Drop rows where labels are not found (unlabeled data)\n",
    "# labeled_data = merged_df.dropna(subset=['Label']).copy()\n",
    "\n",
    "# # Encode labels as numerical values for classifier training\n",
    "# label_mapping = {'Music': 0, 'Dialogue': 1, 'Both': 0}\n",
    "# labeled_data.loc[:, 'Label'] = labeled_data['Label'].map(label_mapping).astype(int)\n",
    "\n",
    "# # Separate features and labels\n",
    "# X = labeled_data.drop(columns=['Filename', 'Label', 'Source'])\n",
    "# y = labeled_data['Label'].astype(int)\n",
    "\n",
    "# # Check the labels for any issues\n",
    "# print(\"Unique labels in y:\", y.unique())\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Initialize and train the Random Forest classifier\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Random Forest Accuracy: {accuracy:.2f}\")\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# # Save the trained model (optional)\n",
    "# joblib.dump(rf_classifier, 'random_forest_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2eb2f5b-16b7-45dc-a870-16638429c1c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_audio_id-venv-9ab27db4d3",
   "language": "python",
   "name": "ml_audio_id-venv-9ab27db4d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
