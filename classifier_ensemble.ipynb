{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c6e08c7-6398-4e38-86a5-3558f3bf50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "694e5d68-dd34-4c90-a342-1b943b88e2e5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y: [1 0]\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Random Forest Accuracy after Tuning: 0.90\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        44\n",
      "           1       0.88      0.92      0.90        39\n",
      "\n",
      "    accuracy                           0.90        83\n",
      "   macro avg       0.90      0.90      0.90        83\n",
      "weighted avg       0.90      0.90      0.90        83\n",
      "\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Gradient Boosting Accuracy after Tuning: 0.92\n",
      "\n",
      "Gradient Boosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.90      0.92      0.91        39\n",
      "\n",
      "    accuracy                           0.92        83\n",
      "   macro avg       0.92      0.92      0.92        83\n",
      "weighted avg       0.92      0.92      0.92        83\n",
      "\n",
      "Ensemble Classifier Accuracy after Tuning: 0.92\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        44\n",
      "           1       0.90      0.92      0.91        39\n",
      "\n",
      "    accuracy                           0.92        83\n",
      "   macro avg       0.92      0.92      0.92        83\n",
      "weighted avg       0.92      0.92      0.92        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "features_labels_file = './features_with_filename_some_labels_241106.csv'\n",
    "\n",
    "merged_df = pd.read_csv(features_labels_file)\n",
    "\n",
    "# Drop rows where labels are not found (unlabeled data)\n",
    "labeled_data = merged_df.dropna(subset=['Label']).copy()\n",
    "unlabeled_data = merged_df[merged_df['Label'].isna()].copy()\n",
    "\n",
    "# Encode labels as numerical values for classifier training\n",
    "label_mapping = {'Music': 0, 'Dialogue': 1, 'Both': 0}\n",
    "labeled_data.loc[:, 'Label'] = labeled_data['Label'].map(label_mapping).astype(int)\n",
    "\n",
    "# Separate features and labels\n",
    "X = labeled_data.drop(columns=['Filename', 'Label', 'Source'])\n",
    "y = labeled_data['Label'].astype(int)\n",
    "\n",
    "# Check the labels for any issues\n",
    "print(\"Unique labels in y:\", y.unique())\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest using RandomizedSearchCV\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [50, 100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_dist_rf, n_iter=20, cv=3, n_jobs=-1, verbose=1, random_state=42)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator from the grid search for Random Forest\n",
    "best_rf_classifier = random_search_rf.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the Random Forest\n",
    "y_pred_rf = best_rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy after Tuning: {accuracy_rf:.2f}\")\n",
    "print(\"\\nRandom Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Hyperparameter tuning for Gradient Boosting using RandomizedSearchCV\n",
    "param_dist_gb = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10]\n",
    "}\n",
    "\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "random_search_gb = RandomizedSearchCV(estimator=gb_classifier, param_distributions=param_dist_gb, n_iter=20, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Get the best estimator from the grid search for Gradient Boosting\n",
    "best_gb_classifier = random_search_gb.best_estimator_\n",
    "\n",
    "# Make predictions on the test set using the Gradient Boosting classifier\n",
    "y_pred_gb = best_gb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "print(f\"Gradient Boosting Accuracy after Tuning: {accuracy_gb:.2f}\")\n",
    "print(\"\\nGradient Boosting Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n",
    "\n",
    "# Create an ensemble using VotingClassifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', best_rf_classifier),\n",
    "    ('gb', best_gb_classifier)\n",
    "], voting='soft', weights=[1, 2])\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set using the ensemble model\n",
    "y_pred = voting_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Ensemble Classifier Accuracy after Tuning: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bfd91f-723a-4a07-8eff-066c6da10cec",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Predict labels for the unlabeled data\n",
    "X_unlabeled = unlabeled_data.drop(columns=['Filename', 'Label', 'Source'], errors='ignore')\n",
    "y_unlabeled_pred = voting_classifier.predict(X_unlabeled)\n",
    "\n",
    "# Add predictions to the unlabeled data\n",
    "unlabeled_data['Predicted_Label'] = y_unlabeled_pred\n",
    "\n",
    "# Map predicted labels back to original categories\n",
    "reverse_label_mapping = {0: 'Music', 1: 'Dialogue'}\n",
    "unlabeled_data['Predicted_Label'] = unlabeled_data['Predicted_Label'].map(reverse_label_mapping)\n",
    "\n",
    "# Create m3u playlists for the predicted labels\n",
    "with open('music_both.m3u', 'w') as music_playlist:\n",
    "    music_playlist.write('#EXTM3U\\n')\n",
    "    for _, row in unlabeled_data.iterrows():\n",
    "        if row['Predicted_Label'] == 'Music':\n",
    "            music_playlist.write(f\"{row['Filename']}\\n\")\n",
    "\n",
    "with open('dialogue.m3u', 'w') as dialogue_playlist:\n",
    "    dialogue_playlist.write('#EXTM3U\\n')\n",
    "    for _, row in unlabeled_data.iterrows():\n",
    "        if row['Predicted_Label'] == 'Dialogue':\n",
    "            dialogue_playlist.write(f\"{row['Filename']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108ff0a-d9d8-4adf-9d76-5a629fd1c5b0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Save the trained models (optional)\n",
    "joblib.dump(best_rf_classifier, 'random_forest_classifier.pkl')\n",
    "joblib.dump(best_gb_classifier, 'gradient_boosting_classifier.pkl')\n",
    "joblib.dump(voting_classifier, 'voting_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0614d660-44b1-4471-ad2a-fabb90e4efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import IPython.display as ipd\n",
    "import time\n",
    "from pathlib import Path\n",
    "from audio_features import read_classifications\n",
    "\n",
    "def play_and_classify_m3u(m3u_file, output_file=None, num_tracks=20):\n",
    "    \"\"\"\n",
    "    Play a specified or random number of items from an M3U file, ask user to classify as M, D, B, \n",
    "    and record the values in a file, displaying the ratio of M, D, B.\n",
    "    Press 'Q' to quit at any time.\n",
    "    \n",
    "    Parameters:\n",
    "    m3u_file (str or Path): Path to the M3U file.\n",
    "    output_file (str or Path): Path to the output file where classifications are saved.\n",
    "    num_tracks (int, optional): Number of tracks to play. If None, a random number of tracks will be played.\n",
    "    \"\"\"\n",
    "    m3u_file = Path(m3u_file)\n",
    "\n",
    "    if not output_file:\n",
    "        output_file = m3u_file.parent / (m3u_file.stem + '_classification.csv')\n",
    "    else:\n",
    "        output_file = Path(output_file)\n",
    "    \n",
    "    # Read M3U file\n",
    "    with m3u_file.open('r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Filter lines to get only filenames (skip #EXTM3U and other comments)\n",
    "    tracks = [line.strip() for line in lines if not line.startswith('#')]\n",
    "    \n",
    "    # Read existing classifications if the output file exists\n",
    "    classified_tracks = set()\n",
    "    classifications = {'M': 0, 'D': 0, 'B': 0}\n",
    "    if output_file.exists():\n",
    "        classified_df = pd.read_csv(output_file)\n",
    "        classified_tracks.update(classified_df['Filename'].tolist())\n",
    "        # Update the classification counts with existing data\n",
    "        existing_classifications = classified_df['Classification'].value_counts().to_dict()\n",
    "        for key in ['M', 'D', 'B']:\n",
    "            if key in existing_classifications:\n",
    "                classifications[key] += existing_classifications[key]\n",
    "    else:\n",
    "        with output_file.open('w') as out_file:\n",
    "            out_file.write('Filename,Classification\\n')\n",
    "    \n",
    "    # Filter out tracks that have already been classified\n",
    "    tracks_to_play = [track for track in tracks if track not in classified_tracks]\n",
    "    \n",
    "    # Randomly shuffle the list of tracks to play\n",
    "    random.shuffle(tracks_to_play)\n",
    "    \n",
    "    # Determine the number of tracks to play\n",
    "    num_tracks = min(num_tracks, len(tracks_to_play))\n",
    "    \n",
    "    # Open output file for appending classifications\n",
    "    classification_map = {\n",
    "        'M': 'Music',\n",
    "        'B': 'Both',\n",
    "        'D': 'Dialogue',\n",
    "        'Q': 'Quit',\n",
    "    }\n",
    "\n",
    "    classifications = {\n",
    "        'B': 0,\n",
    "        'M': 0,\n",
    "        'D': 0\n",
    "    }\n",
    "    \n",
    "    with output_file.open('a') as out_file:\n",
    "        # Play each track and ask for classification\n",
    "        for i in range(num_tracks):\n",
    "            track = tracks_to_play[i]\n",
    "            print(f\"Playing track {i + 1} of {num_tracks}: {track}\")\n",
    "            \n",
    "            # Automatically play the audio file\n",
    "            audio = ipd.Audio(track, autoplay=True)\n",
    "            display_handle = ipd.display(audio, display_id=True)\n",
    "            \n",
    "            # Get user classification (M, D, B, or Q to quit)\n",
    "            classification = None\n",
    "            while classification not in classification_map.keys():\n",
    "                classification = input(\"Classify this track as M (Music), D (Dialogue), B (Both), or Q (Quit): \").upper()\n",
    "                if classification == 'Q':\n",
    "                    print(\"Quitting...\")\n",
    "                    return\n",
    "            \n",
    "            # Record classification if not quitting\n",
    "            if classification != 'Q':\n",
    "                classifications[classification] += 1\n",
    "                out_file.write(f\"{track},{classification_map[classification]}\\n\")\n",
    "            \n",
    "            # Pause between tracks\n",
    "            time.sleep(1)\n",
    "            display_handle.update(ipd.HTML(''))\n",
    "    \n",
    "    # Calculate and display ratio of classifications\n",
    "    total_classifications = sum(classifications.values())\n",
    "    print(\"\\nClassification Ratios:\")\n",
    "    for key, value in classifications.items():\n",
    "        ratio = value / total_classifications if total_classifications > 0 else 0\n",
    "        print(f\"{key}: {ratio:.2f}\")\n",
    "    dialog_pct = classifications[\"D\"] / total_classifications\n",
    "    music_both_pct = (classifications[\"M\"] + classifications[\"B\"]) / total_classifications\n",
    "    print(f\"Music & Both: {music_both_pct * 100}; Dialogue: {dialog_pct * 100}\")\n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391ecdc-cce1-405a-86e6-0dea5eddd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_and_classify_m3u('./dialogue.m3u')\n",
    "\n",
    "play_and_classify_m3u('./music_both.m3u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0837f600-53b3-4002-8791-b81d91042b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'Music': 0, 'Dialogue': 39, 'Both': 1}, {'Music & Both': 0.025, 'Dialogue': 0.975})\n",
      "({'Music': 13, 'Dialogue': 1, 'Both': 26}, {'Music & Both': 0.975, 'Dialogue': 0.025})\n"
     ]
    }
   ],
   "source": [
    "print(read_classifications('./dialogue_classification.csv'))\n",
    "print(read_classifications('./music_both_classification.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80097b-af31-4fe6-ac59-c593dd2647b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_audio_id-venv-9ab27db4d3",
   "language": "python",
   "name": "ml_audio_id-venv-9ab27db4d3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
